{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0dab0f7a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-15T06:34:50.289512Z",
     "start_time": "2024-07-15T06:34:50.253872Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ntextbrewer implemented knowledge distillation\\ntextbrewer package: 一个用于nlp模型的知识蒸馏工具包，旨在简化和加速模型蒸馏过程。\\n- 知识蒸馏是一种技术，通过将pre-trained模型(teacher model)的知识转移到较小的模型(student model)，从而在保留性能的同时减少计算资源消耗。\\nimport textbrewer\\nfrom textbrewer import Generalstiller  # 用于执行通用的知识蒸馏过程。它支持多种蒸馏配置和训练配置，适用于大多数蒸馏场景。\\n# TrainingConfig用于配置训练过程中的一些参数，比如lr、batch_size、epochs等; DistillationConfig用于配置蒸馏过程参数，比如Temperature、alpha等。\\nfrom textbrewer import TrainingConfig, DistillationConfig\\n\\nimport torch\\nfrom transformers import BertForSequenceClassification, AdamW\\n\\n# 定义teacher model和student model\\nteacher_model = BertForSequenceClassification.from_pretrained('bert-base-uncased')\\nstudent_model = BertForSequenceClassification.from_pretrained('distillbert-base-uncased')\\n\\n# 定义优化器\\noptimizer = AdamW(student_model.parameters(), lr=5e-5)\\n\\n# 定义数据加载器\\ntrain_dataloader = ...\\ntest_dataloader = ...\\n\\n# 定义训练配置\\ntraining_config = TrainingConfig(\\n    gradient_accumulation_steps=1,\\n    ckpt_frequency=1,\\n)\\n\\n# 定义蒸馏配置\\ndistillation_config = DistillationConfig(\\n    temperature=4.0,\\n    intermediate_matches=[]  # 可以定义中间层匹配\\n)\\n\\n# 创建蒸馏器\\ndistiller = GeneralDistiller(\\n    train_config=training_config,\\n    distill_config=distillation_config,\\n    model_T=teacher_model,\\n    model_S=student_model,\\n)\\n\\n# 开始蒸馏训练\\nwith distiller:\\n    distiller.train(\\n        optimizer=optimizer,\\n        dataloader=train_dataloader,\\n        num_epochs=3,\\n        callback=None,\\n    )\\n\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "textbrewer implemented knowledge distillation\n",
    "textbrewer package: 一个用于nlp模型的知识蒸馏工具包，旨在简化和加速模型蒸馏过程。\n",
    "- 知识蒸馏是一种技术，通过将pre-trained模型(teacher model)的知识转移到较小的模型(student model)，从而在保留性能的同时减少计算资源消耗。\n",
    "import textbrewer\n",
    "from textbrewer import Generalstiller  # 用于执行通用的知识蒸馏过程。它支持多种蒸馏配置和训练配置，适用于大多数蒸馏场景。\n",
    "# TrainingConfig用于配置训练过程中的一些参数，比如lr、batch_size、epochs等; DistillationConfig用于配置蒸馏过程参数，比如Temperature、alpha等。\n",
    "from textbrewer import TrainingConfig, DistillationConfig\n",
    "\n",
    "import torch\n",
    "from transformers import BertForSequenceClassification, AdamW\n",
    "\n",
    "# 定义teacher model和student model\n",
    "teacher_model = BertForSequenceClassification.from_pretrained('bert-base-uncased')\n",
    "student_model = BertForSequenceClassification.from_pretrained('distillbert-base-uncased')\n",
    "\n",
    "# 定义优化器\n",
    "optimizer = AdamW(student_model.parameters(), lr=5e-5)\n",
    "\n",
    "# 定义数据加载器\n",
    "train_dataloader = ...\n",
    "test_dataloader = ...\n",
    "\n",
    "# 定义训练配置\n",
    "training_config = TrainingConfig(\n",
    "    gradient_accumulation_steps=1,\n",
    "    ckpt_frequency=1,\n",
    ")\n",
    "\n",
    "# 定义蒸馏配置\n",
    "distillation_config = DistillationConfig(\n",
    "    temperature=4.0,\n",
    "    intermediate_matches=[]  # 可以定义中间层匹配\n",
    ")\n",
    "\n",
    "# 创建蒸馏器\n",
    "distiller = GeneralDistiller(\n",
    "    train_config=training_config,\n",
    "    distill_config=distillation_config,\n",
    "    model_T=teacher_model,\n",
    "    model_S=student_model,\n",
    ")\n",
    "\n",
    "# 开始蒸馏训练\n",
    "with distiller:\n",
    "    distiller.train(\n",
    "        optimizer=optimizer,\n",
    "        dataloader=train_dataloader,\n",
    "        num_epochs=3,\n",
    "        callback=None,\n",
    "    )\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a023855f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-13T04:39:33.835002Z",
     "start_time": "2024-07-13T04:39:33.823056Z"
    }
   },
   "source": [
    "## KD_msra_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42eec536",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-15T08:01:31.864964Z",
     "start_time": "2024-07-15T08:01:31.861162Z"
    }
   },
   "outputs": [],
   "source": [
    "# 序列标注任务-命名实体识别NER: https://github.com/airaria/TextBrewer/blob/master/examples/notebook_examples/msra_ner.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d0186ed",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-15T08:01:46.322560Z",
     "start_time": "2024-07-15T08:01:34.380781Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "\n",
    "from transformers import BertForSequenceClassification, BertTokenizer,BertConfig,BertForTokenClassification\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers import pipeline, AutoTokenizer\n",
    "\n",
    "from datasets import load_dataset,load_metric\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aff58e18",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-15T08:01:46.327888Z",
     "start_time": "2024-07-15T08:01:46.324532Z"
    }
   },
   "outputs": [],
   "source": [
    "device='cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe65df2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-13T05:11:53.243133Z",
     "start_time": "2024-07-13T05:11:53.239371Z"
    }
   },
   "source": [
    "### prepare dataset to train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d84adad0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-15T08:01:53.661043Z",
     "start_time": "2024-07-15T08:01:47.428912Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\Lib\\site-packages\\datasets\\load.py:1461: FutureWarning: The repository for msra_ner contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/msra_ner\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "task = \"ner\" #  \"ner\", \"pos\" or \"chunk\"\n",
    "model_checkpoint = \"bert-base-chinese\"\n",
    "batch_size = 8\n",
    "\n",
    "datasets = load_dataset(\"msra_ner\")\n",
    "# 从datasets中获取train datset -> 获取features特征，这是一个dict，f\"{task}_tags\"是f-straing语法，将task变量值嵌入到string中，\n",
    "# 以动态生成feature名称。-> feature获取特征的具体描述 -> names 获取标签名称列表list。\n",
    "label_list = datasets[\"train\"].features[f\"{task}_tags\"].feature.names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "17903ac1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-15T08:01:53.667348Z",
     "start_time": "2024-07-15T08:01:53.664033Z"
    }
   },
   "outputs": [],
   "source": [
    "# map方法对train_dataset进行预处理操作，尤其是使用tokenizer对数据集中的文本进行分词、截断和填充操作。\n",
    "# tokenizer分词对象，来自transformers.BertTokenizer或RobertaTokenizer; truncation=True对长度超过max_length的文本进行截断；padding填充到最大长度。\n",
    "# batched=True，表示map方法每次处理一个batch的数据，而不是一次处理一个数据。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "91f9c502",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-15T08:02:01.412082Z",
     "start_time": "2024-07-15T08:02:01.404668Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': (45001, 3), 'test': (3443, 3)}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "beed6d0e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-15T08:02:02.407239Z",
     "start_time": "2024-07-15T08:02:02.402720Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1244fa27",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-15T08:02:04.357234Z",
     "start_time": "2024-07-15T08:02:03.907731Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afd7e327",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-13T11:46:56.415645Z",
     "start_time": "2024-07-13T11:46:56.411981Z"
    }
   },
   "source": [
    "### utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a8aa7289",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-15T08:02:09.251207Z",
     "start_time": "2024-07-15T08:02:09.245628Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n命名实体识别NER任务中:\\nproblem: tokenizer subword, 即一个word被过度细分成几个subwords，e.g. 单词sheepmeat，被分成3个subtokens: \\'sheep\\',\\'##me\\',\\'##at\\'.\\n        由于label通常是在word级别进行标注的，既然word还会被切分成subtokens，那么意味着我们还需要对label进行subtokens的对齐。\\n        由于pre-trained model输入格式的要求，往往还需要加入一些特殊符号: [CLS], [SEP].\\n        len(example[f\"{task}_tags\"]), len(tokenized_input[\"input_ids\"]) -> (31, 39)\\nsolution: tokenizer.word_ids()方法可以帮助我们解决这个对齐问题。\\n        word_ids() return: [None, 0, 1, 1, 2, 3, 4, 5, 6, 7, 7, 8, 9, 10, 11, 11, 11, 12, 13, 14, 15, 16, 17, 18, 18, 18, None]\\n        可以看到，word_ids将每一个subtokens位置都对应了一个word的下标。比如第一个位置对应第0个word，第2、3个位置对应第1个word，特殊字符对应none。\\n        \\n我们通常将特殊字符的label设置为-100，在模型中-100通常会被忽略掉不计算loss。\\n两种对齐label的方式:\\n- 多个subtokens对齐一个token，对齐一个label。\\n- 多个subtokens的第一个subtoken对齐word，对齐一个label，其他subtokens直接赋予-100.\\n提供了这两种方式，通过label_all_tokens = True 切换\\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "命名实体识别NER任务中:\n",
    "problem: tokenizer subword, 即一个word被过度细分成几个subwords，e.g. 单词sheepmeat，被分成3个subtokens: 'sheep','##me','##at'.\n",
    "        由于label通常是在word级别进行标注的，既然word还会被切分成subtokens，那么意味着我们还需要对label进行subtokens的对齐。\n",
    "        由于pre-trained model输入格式的要求，往往还需要加入一些特殊符号: [CLS], [SEP].\n",
    "        len(example[f\"{task}_tags\"]), len(tokenized_input[\"input_ids\"]) -> (31, 39)\n",
    "solution: tokenizer.word_ids()方法可以帮助我们解决这个对齐问题。\n",
    "        word_ids() return: [None, 0, 1, 1, 2, 3, 4, 5, 6, 7, 7, 8, 9, 10, 11, 11, 11, 12, 13, 14, 15, 16, 17, 18, 18, 18, None]\n",
    "        可以看到，word_ids将每一个subtokens位置都对应了一个word的下标。比如第一个位置对应第0个word，第2、3个位置对应第1个word，特殊字符对应none。\n",
    "        \n",
    "我们通常将特殊字符的label设置为-100，在模型中-100通常会被忽略掉不计算loss。\n",
    "两种对齐label的方式:\n",
    "- 多个subtokens对齐一个token，对齐一个label。\n",
    "- 多个subtokens的第一个subtoken对齐word，对齐一个label，其他subtokens直接赋予-100.\n",
    "提供了这两种方式，通过label_all_tokens = True 切换\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "00fccf85",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-15T08:02:12.110014Z",
     "start_time": "2024-07-15T08:02:12.103269Z"
    }
   },
   "outputs": [],
   "source": [
    "# 对input text进行分词和labels对齐\n",
    "def tokenize_and_align_labels(examples):  # examples对应原始tokens indices\n",
    "    # examples: 输入样本；truncation=True对长度超过max_length的文本进行截断; is_split_into_words表示输入是预先分词的。\n",
    "    tokenized_inputs = tokenizer(examples[\"tokens\"], truncation=True, is_split_into_words=True)  # 返回分词后的结果\n",
    "    print('label before: {tokenized_inputs}')\n",
    "    labels = []\n",
    "    # 遍历样本\n",
    "    for i, label in enumerate(examples[f\"{task}_tags\"]):  # i -> index; tags表示label\n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=i)  # word_idx获取分词后每个index对应的原始单词的索引indices\n",
    "        previous_word_idx = None\n",
    "        label_ids = []\n",
    "        for word_idx in word_ids:  # 每个单词的index\n",
    "            # Special tokens have a word id that is None. We set the label to -100 so they are automatically\n",
    "            # ignored in the loss function.\n",
    "            if word_idx is None:  # index=None，表示特殊标记，[CLS], [SEP], label set -100.\n",
    "                label_ids.append(-100)\n",
    "            # We set the label for the first token of each word.\n",
    "            elif word_idx != previous_word_idx:\n",
    "                label_ids.append(label[word_idx])\n",
    "            # For the other tokens in a word, we set the label to either the current label or -100, depending on\n",
    "            # the label_all_tokens flag.\n",
    "            else:\n",
    "                label_ids.append(label[word_idx] if label_all_tokens else -100)  # 两种对齐方式\n",
    "            previous_word_idx = word_idx\n",
    "\n",
    "        labels.append(label_ids)\n",
    "\n",
    "    tokenized_inputs[\"labels\"] = labels\n",
    "    print('label after: {tokenized_inputs}')\n",
    "    return tokenized_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7a523c71",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-15T08:02:13.248353Z",
     "start_time": "2024-07-15T08:02:13.241765Z"
    }
   },
   "outputs": [],
   "source": [
    "# label_list: ['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC']\n",
    "def compute_metrics(p):  # p是一个包含pred和label的对象，由transformers.Trainer输出\n",
    "    print(p.__dict__)\n",
    "    predictions = p.predictions\n",
    "    labels = p.label_ids\n",
    "    predictions = np.argmax(predictions, axis=2)  # 选择分类概率最大的下标\n",
    "\n",
    "    # Remove ignored index (special tokens): -100\n",
    "    true_predictions = [\n",
    "        [label_list[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)  # batch, batch的\n",
    "    ]\n",
    "    true_labels = [\n",
    "        [label_list[l] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "\n",
    "    results = metric.compute(predictions=true_predictions, references=true_labels)\n",
    "    return {\n",
    "        \"precision\": results[\"overall_precision\"],\n",
    "        \"recall\": results[\"overall_recall\"],\n",
    "        \"f1\": results[\"overall_f1\"],\n",
    "        \"accuracy\": results[\"overall_accuracy\"],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ab2350da",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-15T08:02:13.798348Z",
     "start_time": "2024-07-15T08:02:13.792145Z"
    }
   },
   "outputs": [],
   "source": [
    "def compute_eval_metrics(p):\n",
    "    print(p.__dict__)\n",
    "    predictions = p.predictions[0]  # 这里predictions是一个元组或list，取第一个元素。\n",
    "    labels = p.label_ids\n",
    "    predictions = np.argmax(predictions, axis=2)\n",
    "\n",
    "    # Remove ignored index (special tokens)\n",
    "    true_predictions = [\n",
    "        [label_list[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    true_labels = [\n",
    "        [label_list[l] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "\n",
    "    results = metric.compute(predictions=true_predictions, references=true_labels)\n",
    "    return {\n",
    "        \"precision\": results[\"overall_precision\"],\n",
    "        \"recall\": results[\"overall_recall\"],\n",
    "        \"f1\": results[\"overall_f1\"],\n",
    "        \"accuracy\": results[\"overall_accuracy\"],\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b5ed4c7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-15T02:48:23.229002Z",
     "start_time": "2024-07-15T02:48:23.225003Z"
    }
   },
   "source": [
    "### teacher model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a14c8926",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-15T08:02:17.584445Z",
     "start_time": "2024-07-15T08:02:15.404835Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-chinese and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForTokenClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(21128, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=7, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "- BertForTokenClassfication是transformers中一个用于序列标注任务的模型，它是基于BERT模型，并在其上加了一个linear层，用于每个输入token的分类。\n",
    "- TrainingArguments是transformers中用于配置training过程的参数类，e.g. lr, batch_size, epochs.\n",
    "- Trainer是transformers中用于训练和评估模型的高级api，支持分布式训练。它封装了training和eval过程，简化了模型训练流程。\n",
    "e.g.\n",
    "# 初始化模型\n",
    "model = BertForTokenClassification.from_pretrained(\"bert-base-uncased\", num_labels=9)\n",
    "\n",
    "# 定义训练参数\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=3,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=10,\n",
    ")\n",
    "\n",
    "# 定义训练数据集和评估数据集（假设已经定义好了 train_dataset 和 eval_dataset）\n",
    "train_dataset = ...\n",
    "eval_dataset = ...\n",
    "\n",
    "# 初始化 Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    compute_metrics=compute_metrics,  # 假设已经定义好了 compute_metrics 函数\n",
    ")\n",
    "\n",
    "# 开始训练\n",
    "trainer.train()\n",
    "'''\n",
    "\n",
    "from transformers import BertForTokenClassification, TrainingArguments, Trainer\n",
    "\n",
    "model = BertForTokenClassification.from_pretrained(model_checkpoint, num_labels=len(label_list))\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aa5de994",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-15T08:02:17.590493Z",
     "start_time": "2024-07-15T08:02:17.586439Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForTokenClassification  # 创建数据整理器data collator，用于序列标注任务\n",
    "'''\n",
    "Data collator数据整理器负责将batch数据整理成适合模型输入的格式。\n",
    "在序列标注任务中，每个输入样本可能有不同的长度，因此需要进行填充padding以保持batch内所有样本长度一致。\n",
    "tokenizer是一个分词器实例，用于处理文本数据。它的作用包括：\n",
    "- 将文本转换为词汇表中的索引index\n",
    "- 添加特殊标记[CLS], [SEP]\n",
    "- 填充padding\n",
    "'''\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7990c212",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-15T08:02:19.790807Z",
     "start_time": "2024-07-15T08:02:18.596067Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yysgz\\AppData\\Local\\Temp\\ipykernel_9740\\3635411994.py:2: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate\n",
      "  metric = load_metric(\"seqeval\")\n",
      "D:\\Anaconda3\\Lib\\site-packages\\datasets\\load.py:756: FutureWarning: The repository for seqeval contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/seqeval/seqeval.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# seqeval是一个专门用于序列标注任务的评估库，主要用于评估NER模型的性能，包含precision, recall, f1-score, accuracy等指标。\n",
    "metric = load_metric(\"seqeval\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f6e479a6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-15T08:02:31.404884Z",
     "start_time": "2024-07-15T08:02:21.091745Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b3c2872dbc84a8486c0f2f25eab6b17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/45001 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label before: {tokenized_inputs}\n",
      "label after: {tokenized_inputs}\n",
      "label before: {tokenized_inputs}\n",
      "label after: {tokenized_inputs}\n",
      "label before: {tokenized_inputs}\n",
      "label after: {tokenized_inputs}\n",
      "label before: {tokenized_inputs}\n",
      "label after: {tokenized_inputs}\n",
      "label before: {tokenized_inputs}\n",
      "label after: {tokenized_inputs}\n",
      "label before: {tokenized_inputs}\n",
      "label after: {tokenized_inputs}\n",
      "label before: {tokenized_inputs}\n",
      "label after: {tokenized_inputs}\n",
      "label before: {tokenized_inputs}\n",
      "label after: {tokenized_inputs}\n",
      "label before: {tokenized_inputs}\n",
      "label after: {tokenized_inputs}\n",
      "label before: {tokenized_inputs}\n",
      "label after: {tokenized_inputs}\n",
      "label before: {tokenized_inputs}\n",
      "label after: {tokenized_inputs}\n",
      "label before: {tokenized_inputs}\n",
      "label after: {tokenized_inputs}\n",
      "label before: {tokenized_inputs}\n",
      "label after: {tokenized_inputs}\n",
      "label before: {tokenized_inputs}\n",
      "label after: {tokenized_inputs}\n",
      "label before: {tokenized_inputs}\n",
      "label after: {tokenized_inputs}\n",
      "label before: {tokenized_inputs}\n",
      "label after: {tokenized_inputs}\n",
      "label before: {tokenized_inputs}\n",
      "label after: {tokenized_inputs}\n",
      "label before: {tokenized_inputs}\n",
      "label after: {tokenized_inputs}\n",
      "label before: {tokenized_inputs}\n",
      "label after: {tokenized_inputs}\n",
      "label before: {tokenized_inputs}\n",
      "label after: {tokenized_inputs}\n",
      "label before: {tokenized_inputs}\n",
      "label after: {tokenized_inputs}\n",
      "label before: {tokenized_inputs}\n",
      "label after: {tokenized_inputs}\n",
      "label before: {tokenized_inputs}\n",
      "label after: {tokenized_inputs}\n",
      "label before: {tokenized_inputs}\n",
      "label after: {tokenized_inputs}\n",
      "label before: {tokenized_inputs}\n",
      "label after: {tokenized_inputs}\n",
      "label before: {tokenized_inputs}\n",
      "label after: {tokenized_inputs}\n",
      "label before: {tokenized_inputs}\n",
      "label after: {tokenized_inputs}\n",
      "label before: {tokenized_inputs}\n",
      "label after: {tokenized_inputs}\n",
      "label before: {tokenized_inputs}\n",
      "label after: {tokenized_inputs}\n",
      "label before: {tokenized_inputs}\n",
      "label after: {tokenized_inputs}\n",
      "label before: {tokenized_inputs}\n",
      "label after: {tokenized_inputs}\n",
      "label before: {tokenized_inputs}\n",
      "label after: {tokenized_inputs}\n",
      "label before: {tokenized_inputs}\n",
      "label after: {tokenized_inputs}\n",
      "label before: {tokenized_inputs}\n",
      "label after: {tokenized_inputs}\n",
      "label before: {tokenized_inputs}\n",
      "label after: {tokenized_inputs}\n",
      "label before: {tokenized_inputs}\n",
      "label after: {tokenized_inputs}\n",
      "label before: {tokenized_inputs}\n",
      "label after: {tokenized_inputs}\n",
      "label before: {tokenized_inputs}\n",
      "label after: {tokenized_inputs}\n",
      "label before: {tokenized_inputs}\n",
      "label after: {tokenized_inputs}\n",
      "label before: {tokenized_inputs}\n",
      "label after: {tokenized_inputs}\n",
      "label before: {tokenized_inputs}\n",
      "label after: {tokenized_inputs}\n",
      "label before: {tokenized_inputs}\n",
      "label after: {tokenized_inputs}\n",
      "label before: {tokenized_inputs}\n",
      "label after: {tokenized_inputs}\n",
      "label before: {tokenized_inputs}\n",
      "label after: {tokenized_inputs}\n",
      "label before: {tokenized_inputs}\n",
      "label after: {tokenized_inputs}\n",
      "label before: {tokenized_inputs}\n",
      "label after: {tokenized_inputs}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a97e2a6d107a43d3af998d407a48644f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3443 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label before: {tokenized_inputs}\n",
      "label after: {tokenized_inputs}\n",
      "label before: {tokenized_inputs}\n",
      "label after: {tokenized_inputs}\n",
      "label before: {tokenized_inputs}\n",
      "label after: {tokenized_inputs}\n",
      "label before: {tokenized_inputs}\n",
      "label after: {tokenized_inputs}\n"
     ]
    }
   ],
   "source": [
    "tokenized_datasets = datasets.map(tokenize_and_align_labels, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0e03a31e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-15T08:02:35.070694Z",
     "start_time": "2024-07-15T08:02:35.065705Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': (45001, 7), 'test': (3443, 7)}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c902208f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-15T08:02:35.835834Z",
     "start_time": "2024-07-15T08:02:35.831315Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'tokens', 'ner_tags', 'input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 45001\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'tokens', 'ner_tags', 'input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 3443\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3b1ae89a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-15T08:02:37.984554Z",
     "start_time": "2024-07-15T08:02:37.974076Z"
    }
   },
   "outputs": [],
   "source": [
    "# 缩减数据规模，降低training时间消耗\n",
    "tokenized_datasets[\"train\"] = tokenized_datasets[\"train\"].select(range(500))\n",
    "tokenized_datasets[\"test\"] = tokenized_datasets[\"test\"].select(range(300))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7b82d211",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-15T08:02:39.135923Z",
     "start_time": "2024-07-15T08:02:39.131427Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': (500, 7), 'test': (300, 7)}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "856bf03a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-15T08:02:40.641435Z",
     "start_time": "2024-07-15T08:02:40.635153Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'tokens', 'ner_tags', 'input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 500\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'tokens', 'ner_tags', 'input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 300\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4bd9b34c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-15T08:02:41.331894Z",
     "start_time": "2024-07-15T08:02:41.312042Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\Lib\\site-packages\\transformers\\training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "args = TrainingArguments(  # TrainingArguments配置训练过程参数\n",
    "    output_dir = f\"test-{task}\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=batch_size,  # training batch size\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    num_train_epochs=2,\n",
    "    weight_decay=0.01,\n",
    "    evaluation_strategy = \"epoch\",  # 评估策略为每个epoch训练周期结束后进行评估\n",
    "#     do_train=True,      # 执行训练过程\n",
    "#     do_eval=True,       # 执行评估过程\n",
    "#     no_cuda=True,      # 是否使用cuda，False表示使用gpu\n",
    "#     load_best_model_at_end=True,  # 表示在训练结束后加载在eval过程中性能最好的model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "029ca53c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-15T08:02:42.866537Z",
     "start_time": "2024-07-15T08:02:42.821634Z"
    }
   },
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"test\"],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f2324bec",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-15T08:10:50.475015Z",
     "start_time": "2024-07-15T08:02:44.358941Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='126' max='126' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [126/126 08:02, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.279432</td>\n",
       "      <td>0.312724</td>\n",
       "      <td>0.435705</td>\n",
       "      <td>0.364111</td>\n",
       "      <td>0.918999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.214606</td>\n",
       "      <td>0.430210</td>\n",
       "      <td>0.561798</td>\n",
       "      <td>0.487277</td>\n",
       "      <td>0.942869</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'predictions': array([[[ 3.1587839e+00, -1.1053336e+00, -7.7257478e-01, ...,\n",
      "         -1.4152177e-01, -6.3647628e-01, -5.7730252e-01],\n",
      "        [-2.2807223e-01,  8.4778100e-02,  6.7771420e-02, ...,\n",
      "          6.3411999e-01,  1.2012570e+00, -3.1364501e-01],\n",
      "        [-8.3442283e-01, -2.0065895e-01, -2.2755417e-01, ...,\n",
      "          6.9223404e-01, -8.3874688e-02,  6.9512576e-01],\n",
      "        ...,\n",
      "        [ 4.2492695e+00, -6.0536838e-01, -4.0749884e-01, ...,\n",
      "          3.3651084e-01, -1.6159770e+00, -1.0073408e+00],\n",
      "        [ 3.9921668e+00, -4.6648353e-01, -3.8017747e-01, ...,\n",
      "          2.5083235e-01, -1.4356084e+00, -1.0719131e+00],\n",
      "        [ 3.8555334e+00, -4.5851111e-01, -3.8321680e-01, ...,\n",
      "          2.5756279e-01, -1.4410714e+00, -1.0734185e+00]],\n",
      "\n",
      "       [[ 3.3740771e+00, -1.1027575e+00, -3.2235649e-01, ...,\n",
      "         -2.6564938e-01, -9.1990644e-01, -4.1914588e-01],\n",
      "        [ 6.0701046e+00, -1.1544365e+00, -9.6927583e-01, ...,\n",
      "         -4.1781992e-01, -1.4902309e+00, -1.4970781e+00],\n",
      "        [ 6.3349104e+00, -1.4608878e+00, -1.3456075e+00, ...,\n",
      "         -4.4451290e-01, -1.6410904e+00, -1.7160965e+00],\n",
      "        ...,\n",
      "        [ 1.5253532e+00, -6.5905386e-01, -6.7082024e-01, ...,\n",
      "          8.2400334e-01, -7.3507154e-01,  3.5860896e-02],\n",
      "        [ 5.7194436e-01, -2.2364874e-01, -2.9129660e-01, ...,\n",
      "          1.4239187e+00, -4.9519351e-01, -2.2480537e-01],\n",
      "        [ 1.2093295e+00, -6.9402093e-01, -2.9042906e-01, ...,\n",
      "          1.1898212e+00, -1.1077977e+00,  2.0259546e-01]],\n",
      "\n",
      "       [[ 5.3132319e+00, -1.0144243e+00, -7.1790689e-01, ...,\n",
      "         -7.1032166e-01, -1.3808713e+00, -1.0416307e+00],\n",
      "        [ 6.5258002e+00, -7.2607112e-01, -1.0558947e+00, ...,\n",
      "         -8.0645370e-01, -1.7656027e+00, -1.6995393e+00],\n",
      "        [ 7.1033359e+00, -1.1050479e+00, -9.7718912e-01, ...,\n",
      "         -1.1040523e+00, -1.7165295e+00, -1.3454596e+00],\n",
      "        ...,\n",
      "        [ 7.2107043e+00, -1.2673959e+00, -1.2406276e+00, ...,\n",
      "         -1.0325545e+00, -2.1033745e+00, -1.1961592e+00],\n",
      "        [ 6.7395010e+00, -1.3106717e+00, -7.0577043e-01, ...,\n",
      "         -7.4066579e-01, -2.2958241e+00, -1.1660893e+00],\n",
      "        [ 3.7815588e+00, -4.7743928e-01, -6.1500794e-01, ...,\n",
      "         -6.9566870e-01, -1.0447900e+00, -1.0315683e+00]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 3.8723526e+00, -1.0850122e+00, -3.3702582e-01, ...,\n",
      "         -4.6968719e-01, -6.3261259e-01, -9.9235177e-01],\n",
      "        [ 4.5653167e+00, -7.2534966e-01, -5.8884370e-01, ...,\n",
      "         -3.6211663e-01, -1.0809600e+00, -1.2335821e+00],\n",
      "        [ 5.7298737e+00, -1.0289764e+00, -4.0877247e-01, ...,\n",
      "         -3.9116022e-01, -1.9759759e+00, -1.1534302e+00],\n",
      "        ...,\n",
      "        [-1.0000000e+02, -1.0000000e+02, -1.0000000e+02, ...,\n",
      "         -1.0000000e+02, -1.0000000e+02, -1.0000000e+02],\n",
      "        [-1.0000000e+02, -1.0000000e+02, -1.0000000e+02, ...,\n",
      "         -1.0000000e+02, -1.0000000e+02, -1.0000000e+02],\n",
      "        [-1.0000000e+02, -1.0000000e+02, -1.0000000e+02, ...,\n",
      "         -1.0000000e+02, -1.0000000e+02, -1.0000000e+02]],\n",
      "\n",
      "       [[ 4.7935319e+00, -1.3478329e+00, -6.4435303e-01, ...,\n",
      "         -5.9285599e-01, -8.4446150e-01, -7.9565042e-01],\n",
      "        [ 6.6507668e+00, -1.0776521e+00, -1.0173676e+00, ...,\n",
      "         -8.6131740e-01, -1.7159173e+00, -1.2927060e+00],\n",
      "        [ 7.3291078e+00, -1.0875958e+00, -1.1168348e+00, ...,\n",
      "         -1.0644853e+00, -1.9278840e+00, -1.1739577e+00],\n",
      "        ...,\n",
      "        [-1.0000000e+02, -1.0000000e+02, -1.0000000e+02, ...,\n",
      "         -1.0000000e+02, -1.0000000e+02, -1.0000000e+02],\n",
      "        [-1.0000000e+02, -1.0000000e+02, -1.0000000e+02, ...,\n",
      "         -1.0000000e+02, -1.0000000e+02, -1.0000000e+02],\n",
      "        [-1.0000000e+02, -1.0000000e+02, -1.0000000e+02, ...,\n",
      "         -1.0000000e+02, -1.0000000e+02, -1.0000000e+02]],\n",
      "\n",
      "       [[ 4.0949917e+00, -1.5496888e+00, -4.1461912e-01, ...,\n",
      "         -6.0258120e-01, -7.9300725e-01, -8.0834478e-01],\n",
      "        [ 6.3952169e+00, -1.0637021e+00, -1.2572761e+00, ...,\n",
      "         -5.7748306e-01, -1.6479633e+00, -1.5137093e+00],\n",
      "        [ 6.9210339e+00, -1.5423398e+00, -1.1816297e+00, ...,\n",
      "         -9.2524844e-01, -1.9538145e+00, -1.5009577e+00],\n",
      "        ...,\n",
      "        [-1.0000000e+02, -1.0000000e+02, -1.0000000e+02, ...,\n",
      "         -1.0000000e+02, -1.0000000e+02, -1.0000000e+02],\n",
      "        [-1.0000000e+02, -1.0000000e+02, -1.0000000e+02, ...,\n",
      "         -1.0000000e+02, -1.0000000e+02, -1.0000000e+02],\n",
      "        [-1.0000000e+02, -1.0000000e+02, -1.0000000e+02, ...,\n",
      "         -1.0000000e+02, -1.0000000e+02, -1.0000000e+02]]], dtype=float32), 'label_ids': array([[-100,    3,    4, ..., -100, -100, -100],\n",
      "       [-100,    0,    0, ..., -100, -100, -100],\n",
      "       [-100,    0,    0, ...,    0,    0, -100],\n",
      "       ...,\n",
      "       [-100,    0,    0, ..., -100, -100, -100],\n",
      "       [-100,    0,    0, ..., -100, -100, -100],\n",
      "       [-100,    0,    0, ..., -100, -100, -100]], dtype=int64), 'inputs': None}\n",
      "{'predictions': array([[[ 3.6872187e+00, -1.1738648e+00, -1.1050293e+00, ...,\n",
      "         -3.6402652e-01, -5.7432073e-01, -6.2029243e-01],\n",
      "        [-9.2838407e-01,  1.1782948e-01, -3.2037604e-01, ...,\n",
      "          4.6006227e-01,  1.9221923e+00, -4.6493098e-01],\n",
      "        [-1.5046225e+00, -5.4829961e-01, -3.6776102e-01, ...,\n",
      "          1.3661888e+00, -1.9406930e-02,  1.1736720e+00],\n",
      "        ...,\n",
      "        [ 4.6790404e+00, -5.9134090e-01, -6.4007306e-01, ...,\n",
      "          1.4610311e-01, -1.5956377e+00, -1.0353996e+00],\n",
      "        [ 4.4453659e+00, -4.3800676e-01, -6.1144227e-01, ...,\n",
      "          5.7622254e-02, -1.3896469e+00, -1.1197903e+00],\n",
      "        [ 4.2956572e+00, -4.2833805e-01, -6.0465193e-01, ...,\n",
      "          6.6200942e-02, -1.3935566e+00, -1.1186856e+00]],\n",
      "\n",
      "       [[ 4.4734564e+00, -1.2233925e+00, -7.3177791e-01, ...,\n",
      "         -5.9770370e-01, -9.8074728e-01, -6.5728390e-01],\n",
      "        [ 6.9261265e+00, -1.1309549e+00, -1.2775290e+00, ...,\n",
      "         -7.9884642e-01, -1.5372438e+00, -1.6104114e+00],\n",
      "        [ 7.2051058e+00, -1.4625653e+00, -1.6369164e+00, ...,\n",
      "         -8.4040457e-01, -1.6374717e+00, -1.7325225e+00],\n",
      "        ...,\n",
      "        [ 2.3884854e+00, -9.3710333e-01, -8.9486867e-01, ...,\n",
      "          6.1474299e-01, -9.5774692e-01, -5.4050289e-02],\n",
      "        [ 1.4736030e+00, -4.7024858e-01, -7.7763885e-01, ...,\n",
      "          1.3069599e+00, -7.1404338e-01, -2.5867432e-01],\n",
      "        [ 2.0311344e+00, -9.4343328e-01, -5.5359179e-01, ...,\n",
      "          1.3574228e+00, -1.4492985e+00,  2.8372315e-01]],\n",
      "\n",
      "       [[ 6.1977549e+00, -9.9546981e-01, -1.1355488e+00, ...,\n",
      "         -1.1219525e+00, -1.4229747e+00, -1.0773902e+00],\n",
      "        [ 7.1760130e+00, -7.9618245e-01, -1.3715283e+00, ...,\n",
      "         -1.1452625e+00, -1.7194996e+00, -1.6671785e+00],\n",
      "        [ 7.7072735e+00, -1.1399411e+00, -1.3320732e+00, ...,\n",
      "         -1.3240039e+00, -1.7066716e+00, -1.3481233e+00],\n",
      "        ...,\n",
      "        [ 7.7537379e+00, -1.3040490e+00, -1.5630991e+00, ...,\n",
      "         -1.2952566e+00, -2.0121591e+00, -1.1526620e+00],\n",
      "        [ 7.5448270e+00, -1.2829298e+00, -1.1554673e+00, ...,\n",
      "         -1.1537802e+00, -2.1540310e+00, -1.3133111e+00],\n",
      "        [ 3.9384749e+00, -4.3072867e-01, -9.0337020e-01, ...,\n",
      "         -9.9503285e-01, -8.2334715e-01, -9.0799856e-01]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 4.5101743e+00, -1.1519212e+00, -7.1707428e-01, ...,\n",
      "         -6.9140089e-01, -6.0569853e-01, -1.0314786e+00],\n",
      "        [ 5.1211467e+00, -6.1890918e-01, -8.7097180e-01, ...,\n",
      "         -6.0252595e-01, -1.0165392e+00, -1.3117509e+00],\n",
      "        [ 6.6305065e+00, -1.0378504e+00, -7.7491891e-01, ...,\n",
      "         -7.4063820e-01, -1.8994262e+00, -1.2390392e+00],\n",
      "        ...,\n",
      "        [-1.0000000e+02, -1.0000000e+02, -1.0000000e+02, ...,\n",
      "         -1.0000000e+02, -1.0000000e+02, -1.0000000e+02],\n",
      "        [-1.0000000e+02, -1.0000000e+02, -1.0000000e+02, ...,\n",
      "         -1.0000000e+02, -1.0000000e+02, -1.0000000e+02],\n",
      "        [-1.0000000e+02, -1.0000000e+02, -1.0000000e+02, ...,\n",
      "         -1.0000000e+02, -1.0000000e+02, -1.0000000e+02]],\n",
      "\n",
      "       [[ 5.4935284e+00, -1.3918486e+00, -1.1286609e+00, ...,\n",
      "         -8.8619709e-01, -8.7760979e-01, -7.9959840e-01],\n",
      "        [ 7.3204403e+00, -1.0937381e+00, -1.3878576e+00, ...,\n",
      "         -1.1969004e+00, -1.6341960e+00, -1.3821054e+00],\n",
      "        [ 7.9159799e+00, -1.1613439e+00, -1.4797821e+00, ...,\n",
      "         -1.3371276e+00, -1.8029418e+00, -1.2202368e+00],\n",
      "        ...,\n",
      "        [-1.0000000e+02, -1.0000000e+02, -1.0000000e+02, ...,\n",
      "         -1.0000000e+02, -1.0000000e+02, -1.0000000e+02],\n",
      "        [-1.0000000e+02, -1.0000000e+02, -1.0000000e+02, ...,\n",
      "         -1.0000000e+02, -1.0000000e+02, -1.0000000e+02],\n",
      "        [-1.0000000e+02, -1.0000000e+02, -1.0000000e+02, ...,\n",
      "         -1.0000000e+02, -1.0000000e+02, -1.0000000e+02]],\n",
      "\n",
      "       [[ 4.9069629e+00, -1.4774853e+00, -7.5345170e-01, ...,\n",
      "         -8.9601904e-01, -8.2613492e-01, -9.1519558e-01],\n",
      "        [ 7.1459966e+00, -1.0500379e+00, -1.5476139e+00, ...,\n",
      "         -9.4601023e-01, -1.6235160e+00, -1.5693376e+00],\n",
      "        [ 7.5990338e+00, -1.5060521e+00, -1.5058198e+00, ...,\n",
      "         -1.2112308e+00, -1.8662562e+00, -1.5403892e+00],\n",
      "        ...,\n",
      "        [-1.0000000e+02, -1.0000000e+02, -1.0000000e+02, ...,\n",
      "         -1.0000000e+02, -1.0000000e+02, -1.0000000e+02],\n",
      "        [-1.0000000e+02, -1.0000000e+02, -1.0000000e+02, ...,\n",
      "         -1.0000000e+02, -1.0000000e+02, -1.0000000e+02],\n",
      "        [-1.0000000e+02, -1.0000000e+02, -1.0000000e+02, ...,\n",
      "         -1.0000000e+02, -1.0000000e+02, -1.0000000e+02]]], dtype=float32), 'label_ids': array([[-100,    3,    4, ..., -100, -100, -100],\n",
      "       [-100,    0,    0, ..., -100, -100, -100],\n",
      "       [-100,    0,    0, ...,    0,    0, -100],\n",
      "       ...,\n",
      "       [-100,    0,    0, ..., -100, -100, -100],\n",
      "       [-100,    0,    0, ..., -100, -100, -100],\n",
      "       [-100,    0,    0, ..., -100, -100, -100]], dtype=int64), 'inputs': None}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=126, training_loss=0.14215729728577628, metrics={'train_runtime': 485.4054, 'train_samples_per_second': 2.06, 'train_steps_per_second': 0.26, 'total_flos': 39841390815072.0, 'train_loss': 0.14215729728577628, 'epoch': 2.0})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "50059163",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-15T08:12:38.761880Z",
     "start_time": "2024-07-15T08:12:38.346018Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), './outputs/msra_teacher_model.pt')  # save the teacher model weights to distill"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b5ff30f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-13T05:21:14.403854Z",
     "start_time": "2024-07-13T05:21:14.400870Z"
    }
   },
   "source": [
    "### knowledge distillation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "38b0579d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-15T08:12:40.783972Z",
     "start_time": "2024-07-15T08:12:40.764355Z"
    }
   },
   "outputs": [],
   "source": [
    "import textbrewer\n",
    "from textbrewer import GeneralDistiller\n",
    "from textbrewer import TrainingConfig, DistillationConfig\n",
    "from transformers import BertForTokenClassification, BertConfig,BertTokenizer\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from torch.optim import AdamW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9f53b76e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-15T08:12:42.912734Z",
     "start_time": "2024-07-15T08:12:42.906511Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, RandomSampler\n",
    "train_dataset=tokenized_datasets[\"train\"].remove_columns(['id','tokens','ner_tags'])  # 移除列\n",
    "# 创建DataLoader对象，将数据集加载成一个可迭代的对象，以高效批量处理数据。\n",
    "train_dataloader = DataLoader(train_dataset, sampler=RandomSampler(train_dataset), batch_size=32,collate_fn=data_collator) #prepare dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8dc59092",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-15T08:12:45.650462Z",
     "start_time": "2024-07-15T08:12:43.646250Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForTokenClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(21128, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-2): 3 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=7, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "initialize the student model by BertConfig and prepare the teacher model\n",
    "- bert_config_L3.json refers to a 3-layer Bert.\n",
    "- bert_config.json refers to a standard 12-layer Bert.\n",
    "'''\n",
    "# 读取config文件，并配置到student model\n",
    "bert_config_T3 = BertConfig.from_json_file('./config/bert_config_L3.json')  # BertConfig是transformers中用于配置和初始化BERT模型的类。\n",
    "# 设置model在ffd时输出hidden states，这在知识蒸馏中很重要，因为我们要比较studnet和teacher模型的隐藏层输出。\n",
    "bert_config_T3.output_hidden_states = True\n",
    "bert_config_T3.num_labels = len(label_list)  # 设置标签数量，用于分类任务中\n",
    "\n",
    "student_model = BertForTokenClassification(bert_config_T3)  # 初始化student model, 一个bert序列标注模型\n",
    "\n",
    "bert_config = BertConfig.from_json_file('./config/bert_config.json')  # 读取teacher model配置文件\n",
    "bert_config.output_hidden_states = True\n",
    "bert_config.num_labels = len(label_list)\n",
    "\n",
    "teacher_model = BertForTokenClassification(bert_config)   # 初始化teacher model\n",
    "teacher_model.load_state_dict(torch.load('./outputs/msra_teacher_model.pt'))  # 加载trained model权重\n",
    "\n",
    "teacher_model.to(device)\n",
    "student_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d4e66654",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-15T08:12:45.659109Z",
     "start_time": "2024-07-15T08:12:45.653433Z"
    }
   },
   "outputs": [],
   "source": [
    "# 处理batch数据\n",
    "def proc_fn(batch):\n",
    "  return {'input_ids':batch['input_ids'],\n",
    "          'token_type_ids':batch['token_type_ids'],\n",
    "          'attention_mask':batch['attention_mask'],  # 对应哪些token时padding的，哪些是真实数据。\n",
    "          'labels':batch['labels']}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc6c2f43",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-15T03:33:43.945874Z",
     "start_time": "2024-07-15T03:33:43.942507Z"
    }
   },
   "source": [
    "#### textbrewer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "928434ef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-15T08:12:50.772666Z",
     "start_time": "2024-07-15T08:12:50.763403Z"
    }
   },
   "outputs": [],
   "source": [
    "num_epochs = 20\n",
    "num_training_steps = len(train_dataloader) * num_epochs\n",
    "\n",
    "optimizer = AdamW(student_model.parameters(), lr=1e-5)\n",
    "\n",
    "# 学习率调度器\n",
    "scheduler_class = get_linear_schedule_with_warmup  # 使用线性学习率调度器\n",
    "scheduler_args = {'num_warmup_steps':int(0.1*num_training_steps), 'num_training_steps':num_training_steps}  # 预热步数、训练步数\n",
    "\n",
    "# adaptor函数，用于从模型中提取logits和hidden states\n",
    "def simple_adaptor(batch, model_outputs):\n",
    "  return {\"logits\":model_outputs.logits, 'hidden': model_outputs.hidden_states}\n",
    "\n",
    "# 定义蒸馏配置\n",
    "'''\n",
    "intermediate_matches的作用是在知识蒸馏中定义teacher model和student model之间的特征匹配策略。通过这些配置，可以指定在哪些层级上进行\n",
    "    特征匹配，使用什么样的loss来衡量匹配效果，并且可以对不同的匹配进行加权处理，以控制不同层级的重要性。\n",
    "在文本蒸馏中，通常会选择一些中间层的hidden states作为特征进行匹配，帮助student model更好地学习到teacher model的知识。通过调整\n",
    "    intermediate_matches的配置，可以优化知识的传递效果，从而提升student model的性能。\n",
    "- layer_T，是teacher model的层索引index，表示要匹配的是教师模型的哪一层特征。\n",
    "- layer_S，是student model的层索引index，表示教师模型的哪一层特征传递给学生模型的哪一层进行匹配。\n",
    "- feature，指定要匹配的特征类型。\n",
    "'''\n",
    "distill_config = DistillationConfig(\n",
    "    temperature = 4.0,\n",
    "    intermediate_matches=[{\"layer_T\":0, \"layer_S\":0, \"feature\":\"hidden\", \"loss\":\"hidden_mse\", \"weight\":1},\n",
    "               {\"layer_T\":4, \"layer_S\":1, \"feature\":\"hidden\", \"loss\":\"hidden_mse\", \"weight\":1},\n",
    "               {\"layer_T\":8, \"layer_S\":2, \"feature\":\"hidden\", \"loss\":\"hidden_mse\", \"weight\":1},\n",
    "               {\"layer_T\":12,\"layer_S\":3, \"feature\":\"hidden\", \"loss\":\"hidden_mse\", \"weight\":1}])\n",
    "\n",
    "# 训练配置\n",
    "train_config = TrainingConfig(device='cpu')\n",
    "\n",
    "distiller = GeneralDistiller(  # GeneralDistiller初始化一个知识蒸馏器\n",
    "    train_config=train_config, \n",
    "    distill_config=distill_config,\n",
    "    model_T=teacher_model, \n",
    "    model_S=student_model, \n",
    "    adaptor_T=simple_adaptor, \n",
    "    adaptor_S=simple_adaptor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "968f0699",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-15T08:12:51.985136Z",
     "start_time": "2024-07-15T08:12:51.980097Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TrainingConfig:\n",
       "gradient_accumulation_steps : 1\n",
       "ckpt_frequency : 1\n",
       "ckpt_epoch_frequency : 1\n",
       "ckpt_steps : None\n",
       "log_dir : None\n",
       "output_dir : ./saved_models\n",
       "device : cpu\n",
       "fp16 : False\n",
       "fp16_opt_level : O1\n",
       "data_parallel : False\n",
       "local_rank : -1"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ccc67160",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-15T08:54:16.319742Z",
     "start_time": "2024-07-15T08:12:53.452210Z"
    }
   },
   "outputs": [],
   "source": [
    "with distiller:\n",
    "    # distiller.train方法本身不返回任何值，它的作用是执行training过程，并更新学生模型的参数。\n",
    "    # 保存student model，需要在训练结束后手动保存，torch.save(student_model.state_dict(), \"student_model.pth\")\n",
    "    distiller.train(optimizer, train_dataloader, num_epochs, scheduler_class=scheduler_class, \n",
    "                    scheduler_args = scheduler_args, callback=None, batch_postprocessor=proc_fn)  \n",
    "# batch_postprocessor 批处理后处理器，用于在数据从dataloader提取出来后，但在传递给model之前，对数据进行进一步处理。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3d3b84bc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-15T08:54:42.486689Z",
     "start_time": "2024-07-15T08:54:42.210134Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.save(student_model.state_dict(), \"./outputs/msra_student_model.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c85d4215",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-13T11:02:41.494021Z",
     "start_time": "2024-07-13T11:02:41.490858Z"
    }
   },
   "source": [
    "### student model evaluating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c4338103",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-15T08:54:44.180671Z",
     "start_time": "2024-07-15T08:54:43.733119Z"
    }
   },
   "outputs": [],
   "source": [
    "bert_config_T3 = BertConfig.from_json_file('./config/bert_config_L3.json')\n",
    "\n",
    "bert_config_T3.output_hidden_states = True\n",
    "bert_config_T3.num_labels = len(label_list)\n",
    "test_model = BertForTokenClassification(bert_config_T3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "51c584c1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-15T08:55:11.998877Z",
     "start_time": "2024-07-15T08:55:11.850059Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForTokenClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(21128, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-2): 3 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=7, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_model.load_state_dict(torch.load('./saved_models/gs320.pkl'))\n",
    "test_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "57048bde",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-15T08:55:13.274432Z",
     "start_time": "2024-07-15T08:55:13.263567Z"
    }
   },
   "outputs": [],
   "source": [
    "args = TrainingArguments(\n",
    "    f\"distill-test\",\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    do_train=False,\n",
    "    do_eval=True,\n",
    "    no_cuda=False,\n",
    "    num_train_epochs=2,\n",
    "    weight_decay=0.01,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "064803b6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-15T08:55:14.121688Z",
     "start_time": "2024-07-15T08:55:14.097765Z"
    }
   },
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    test_model,\n",
    "    args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"test\"],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_eval_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2f7517f7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-15T08:55:15.305136Z",
     "start_time": "2024-07-15T08:55:15.299623Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ntrainer.train()和trainer.evaluate()是transformers中进行模型训练和评估的方法\\n- trainer.train()方法只使用train_datasets对模型进行训练，更新模型参数，调整学习率。\\n- trainer.evaluate()方法只使用eval_dataset对模型进行评估，不更新参数，不调整学习率。\\n'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "trainer.train()和trainer.evaluate()是transformers中进行模型训练和评估的方法\n",
    "- trainer.train()方法只使用train_datasets对模型进行训练，更新模型参数，调整学习率。\n",
    "- trainer.evaluate()方法只使用eval_dataset对模型进行评估，不更新参数，不调整学习率。\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "93bb1b92",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-15T08:55:42.760490Z",
     "start_time": "2024-07-15T08:55:16.361197Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='38' max='38' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [38/38 00:24]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'predictions': (array([[[   4.1751356 ,   -1.3892034 ,   -0.62786216, ...,\n",
      "           -1.1625446 ,   -1.6603606 ,   -1.0444247 ],\n",
      "        [   4.2052107 ,   -1.0325062 ,   -0.6012637 , ...,\n",
      "           -1.3700162 ,   -1.4891158 ,   -0.9249886 ],\n",
      "        [   4.1645384 ,   -1.3668545 ,   -0.6859249 , ...,\n",
      "           -1.3610991 ,   -1.591393  ,   -1.0895182 ],\n",
      "        ...,\n",
      "        [   4.2748175 ,   -1.3126764 ,   -0.77339554, ...,\n",
      "           -1.236407  ,   -1.6573793 ,   -1.158958  ],\n",
      "        [   4.0912776 ,   -1.2714908 ,   -0.78826404, ...,\n",
      "           -1.3551276 ,   -1.523216  ,   -1.1341921 ],\n",
      "        [   4.135216  ,   -1.3037676 ,   -0.7212115 , ...,\n",
      "           -1.2934223 ,   -1.6777797 ,   -1.1420298 ]],\n",
      "\n",
      "       [[   4.180667  ,   -1.389655  ,   -0.62356436, ...,\n",
      "           -1.173089  ,   -1.6734393 ,   -1.0477221 ],\n",
      "        [   4.2352104 ,   -1.1125957 ,   -0.5626025 , ...,\n",
      "           -1.3212243 ,   -1.5171155 ,   -0.88254654],\n",
      "        [   4.1899295 ,   -1.3223742 ,   -0.6985833 , ...,\n",
      "           -1.3510747 ,   -1.4661715 ,   -0.9766689 ],\n",
      "        ...,\n",
      "        [   4.2781925 ,   -1.3128364 ,   -0.76555663, ...,\n",
      "           -1.2430606 ,   -1.6745667 ,   -1.1576104 ],\n",
      "        [   4.09565   ,   -1.2732117 ,   -0.7816099 , ...,\n",
      "           -1.3576174 ,   -1.5438838 ,   -1.1323848 ],\n",
      "        [   4.1415544 ,   -1.3034371 ,   -0.71536225, ...,\n",
      "           -1.2978927 ,   -1.690341  ,   -1.1403462 ]],\n",
      "\n",
      "       [[   4.1827483 ,   -1.3808202 ,   -0.6356837 , ...,\n",
      "           -1.1542428 ,   -1.6722394 ,   -1.0681288 ],\n",
      "        [   4.267106  ,   -1.1120265 ,   -0.6112566 , ...,\n",
      "           -1.332861  ,   -1.5895522 ,   -1.0043387 ],\n",
      "        [   4.2275815 ,   -1.3295295 ,   -0.6530757 , ...,\n",
      "           -1.2663298 ,   -1.6154585 ,   -1.1162928 ],\n",
      "        ...,\n",
      "        [   4.3449955 ,   -1.4291018 ,   -0.860385  , ...,\n",
      "           -1.1755813 ,   -1.7577181 ,   -1.1624032 ],\n",
      "        [   4.178376  ,   -1.2925589 ,   -0.84674007, ...,\n",
      "           -1.4170523 ,   -1.491022  ,   -1.2671697 ],\n",
      "        [   4.073221  ,   -1.3385913 ,   -0.691782  , ...,\n",
      "           -1.2531159 ,   -1.6105666 ,   -1.2724867 ]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[   4.180576  ,   -1.3668942 ,   -0.6287516 , ...,\n",
      "           -1.181207  ,   -1.6777637 ,   -1.032056  ],\n",
      "        [   4.303441  ,   -1.1555054 ,   -0.6032129 , ...,\n",
      "           -1.2678556 ,   -1.5396454 ,   -1.0982926 ],\n",
      "        [   4.232701  ,   -1.3273733 ,   -0.63037753, ...,\n",
      "           -1.2827593 ,   -1.5525538 ,   -1.0332035 ],\n",
      "        ...,\n",
      "        [-100.        , -100.        , -100.        , ...,\n",
      "         -100.        , -100.        , -100.        ],\n",
      "        [-100.        , -100.        , -100.        , ...,\n",
      "         -100.        , -100.        , -100.        ],\n",
      "        [-100.        , -100.        , -100.        , ...,\n",
      "         -100.        , -100.        , -100.        ]],\n",
      "\n",
      "       [[   4.170189  ,   -1.3970168 ,   -0.63897073, ...,\n",
      "           -1.1705306 ,   -1.6698511 ,   -1.0597705 ],\n",
      "        [   4.174568  ,   -1.2143892 ,   -0.6975614 , ...,\n",
      "           -1.292542  ,   -1.5767483 ,   -1.0379568 ],\n",
      "        [   4.1802435 ,   -1.3557106 ,   -0.7853436 , ...,\n",
      "           -1.3151352 ,   -1.6272695 ,   -1.0252693 ],\n",
      "        ...,\n",
      "        [-100.        , -100.        , -100.        , ...,\n",
      "         -100.        , -100.        , -100.        ],\n",
      "        [-100.        , -100.        , -100.        , ...,\n",
      "         -100.        , -100.        , -100.        ],\n",
      "        [-100.        , -100.        , -100.        , ...,\n",
      "         -100.        , -100.        , -100.        ]],\n",
      "\n",
      "       [[   4.176048  ,   -1.369749  ,   -0.63806075, ...,\n",
      "           -1.1888058 ,   -1.6827481 ,   -1.0642126 ],\n",
      "        [   4.289509  ,   -1.1679511 ,   -0.6975205 , ...,\n",
      "           -1.2035074 ,   -1.4832969 ,   -1.0510521 ],\n",
      "        [   4.2534904 ,   -1.3431109 ,   -0.79877836, ...,\n",
      "           -1.332305  ,   -1.6009061 ,   -1.0019248 ],\n",
      "        ...,\n",
      "        [-100.        , -100.        , -100.        , ...,\n",
      "         -100.        , -100.        , -100.        ],\n",
      "        [-100.        , -100.        , -100.        , ...,\n",
      "         -100.        , -100.        , -100.        ],\n",
      "        [-100.        , -100.        , -100.        , ...,\n",
      "         -100.        , -100.        , -100.        ]]], dtype=float32), (array([[[-8.1418663e-01,  7.9688680e-01, -1.1797385e+00, ...,\n",
      "          2.0869410e+00,  7.0340466e-01,  3.0614963e-01],\n",
      "        [ 8.1171060e-01, -4.9630851e-02,  6.1421955e-01, ...,\n",
      "         -5.2698666e-01,  1.4877282e+00,  1.5947435e+00],\n",
      "        [ 1.3394821e+00, -3.9913476e-02,  2.2301525e-01, ...,\n",
      "          1.0359473e+00,  1.6327622e+00, -8.2682711e-01],\n",
      "        ...,\n",
      "        [ 4.9913228e-02, -8.5102348e-03, -4.9067131e-01, ...,\n",
      "          1.1904927e+00,  1.2398242e+00,  1.4205433e+00],\n",
      "        [-4.0892753e-01,  5.1822677e-02, -1.0742771e-01, ...,\n",
      "          8.8334578e-01,  1.5293539e+00,  6.0999590e-01],\n",
      "        [ 6.7655551e-01,  2.2477055e+00, -3.5474908e-01, ...,\n",
      "          1.0274724e+00,  9.3687266e-01,  1.0208843e+00]],\n",
      "\n",
      "       [[-8.1418663e-01,  7.9688680e-01, -1.1797385e+00, ...,\n",
      "          2.0869410e+00,  7.0340466e-01,  3.0614963e-01],\n",
      "        [-3.5806715e-01, -2.1475311e-01,  9.0613909e-02, ...,\n",
      "          8.8725495e-01,  1.3699292e+00,  1.2057694e+00],\n",
      "        [ 5.5191422e-01, -6.5941587e-02, -4.5717657e-02, ...,\n",
      "          1.4126034e+00,  1.8961375e+00, -3.1891584e-01],\n",
      "        ...,\n",
      "        [ 4.9913228e-02, -8.5102348e-03, -4.9067131e-01, ...,\n",
      "          1.1904927e+00,  1.2398242e+00,  1.4205433e+00],\n",
      "        [-4.0892753e-01,  5.1822677e-02, -1.0742771e-01, ...,\n",
      "          8.8334578e-01,  1.5293539e+00,  6.0999590e-01],\n",
      "        [ 6.7655551e-01,  2.2477055e+00, -3.5474908e-01, ...,\n",
      "          1.0274724e+00,  9.3687266e-01,  1.0208843e+00]],\n",
      "\n",
      "       [[-8.1418663e-01,  7.9688680e-01, -1.1797385e+00, ...,\n",
      "          2.0869410e+00,  7.0340466e-01,  3.0614963e-01],\n",
      "        [ 1.3042357e+00,  5.2796108e-01, -8.4049612e-02, ...,\n",
      "          4.9758908e-01,  1.2629799e+00,  4.6174413e-01],\n",
      "        [ 1.1580758e+00,  4.2417172e-01, -1.3738673e+00, ...,\n",
      "          7.0120853e-01,  9.2341530e-01,  6.0915756e-01],\n",
      "        ...,\n",
      "        [-6.8620378e-01, -5.9329176e-01, -1.5582291e+00, ...,\n",
      "          1.1947864e+00,  1.2205063e+00,  8.3072877e-01],\n",
      "        [-1.3940747e+00,  1.6353866e-02, -1.6640766e-01, ...,\n",
      "          1.3183346e+00,  2.4238555e+00,  2.5202844e-01],\n",
      "        [ 6.3687992e-01,  1.7416984e+00,  4.0516010e-01, ...,\n",
      "         -4.8241624e-01,  5.3280383e-01,  1.1374022e+00]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[-8.1418663e-01,  7.9688680e-01, -1.1797385e+00, ...,\n",
      "          2.0869410e+00,  7.0340466e-01,  3.0614963e-01],\n",
      "        [ 9.3622792e-01, -5.1033545e-01,  8.6782217e-02, ...,\n",
      "         -3.8535336e-01,  1.6558603e+00,  9.7839546e-01],\n",
      "        [-2.1044900e-01,  6.4898026e-01, -7.1601218e-01, ...,\n",
      "          1.3179070e+00,  1.1862646e+00,  9.7395021e-01],\n",
      "        ...,\n",
      "        [-1.0000000e+02, -1.0000000e+02, -1.0000000e+02, ...,\n",
      "         -1.0000000e+02, -1.0000000e+02, -1.0000000e+02],\n",
      "        [-1.0000000e+02, -1.0000000e+02, -1.0000000e+02, ...,\n",
      "         -1.0000000e+02, -1.0000000e+02, -1.0000000e+02],\n",
      "        [-1.0000000e+02, -1.0000000e+02, -1.0000000e+02, ...,\n",
      "         -1.0000000e+02, -1.0000000e+02, -1.0000000e+02]],\n",
      "\n",
      "       [[-8.1418663e-01,  7.9688680e-01, -1.1797385e+00, ...,\n",
      "          2.0869410e+00,  7.0340466e-01,  3.0614963e-01],\n",
      "        [ 4.0413406e-01,  4.1537958e-01,  7.7351958e-02, ...,\n",
      "          1.6737485e+00,  1.3210051e+00,  7.0708859e-01],\n",
      "        [-1.4041263e-01, -3.3393624e-01, -2.1537636e-01, ...,\n",
      "          7.3263210e-01,  1.4573334e+00,  7.6083064e-01],\n",
      "        ...,\n",
      "        [-1.0000000e+02, -1.0000000e+02, -1.0000000e+02, ...,\n",
      "         -1.0000000e+02, -1.0000000e+02, -1.0000000e+02],\n",
      "        [-1.0000000e+02, -1.0000000e+02, -1.0000000e+02, ...,\n",
      "         -1.0000000e+02, -1.0000000e+02, -1.0000000e+02],\n",
      "        [-1.0000000e+02, -1.0000000e+02, -1.0000000e+02, ...,\n",
      "         -1.0000000e+02, -1.0000000e+02, -1.0000000e+02]],\n",
      "\n",
      "       [[-8.1418663e-01,  7.9688680e-01, -1.1797385e+00, ...,\n",
      "          2.0869410e+00,  7.0340466e-01,  3.0614963e-01],\n",
      "        [-5.3093725e-01, -4.2414495e-01,  4.9313581e-01, ...,\n",
      "         -8.2513034e-02,  1.0883288e+00,  1.3181571e+00],\n",
      "        [ 2.3541753e-01, -5.8050781e-01, -1.3515750e-01, ...,\n",
      "          1.6794842e-02,  7.7598625e-01,  6.4910495e-01],\n",
      "        ...,\n",
      "        [-1.0000000e+02, -1.0000000e+02, -1.0000000e+02, ...,\n",
      "         -1.0000000e+02, -1.0000000e+02, -1.0000000e+02],\n",
      "        [-1.0000000e+02, -1.0000000e+02, -1.0000000e+02, ...,\n",
      "         -1.0000000e+02, -1.0000000e+02, -1.0000000e+02],\n",
      "        [-1.0000000e+02, -1.0000000e+02, -1.0000000e+02, ...,\n",
      "         -1.0000000e+02, -1.0000000e+02, -1.0000000e+02]]], dtype=float32), array([[[ 2.19634309e-01, -1.01653588e+00, -1.37627745e+00, ...,\n",
      "          2.05305696e-01,  4.07848321e-02,  4.96370643e-01],\n",
      "        [ 1.29827416e+00, -1.21637857e+00,  5.53663038e-02, ...,\n",
      "         -7.97744989e-01,  1.15591794e-01,  1.24018860e+00],\n",
      "        [ 9.71668959e-01, -1.10995460e+00, -2.54188240e-01, ...,\n",
      "         -3.60793859e-01,  7.57594883e-01, -1.05335750e-01],\n",
      "        ...,\n",
      "        [ 7.18388140e-01, -1.00157118e+00, -7.69103348e-01, ...,\n",
      "         -2.04172619e-02,  4.53894585e-01,  1.36295557e+00],\n",
      "        [ 5.54240286e-01, -9.34968829e-01, -3.34996313e-01, ...,\n",
      "         -4.82513279e-01,  3.92181784e-01,  5.65820336e-01],\n",
      "        [ 9.32018161e-01,  2.77112070e-02, -3.14125538e-01, ...,\n",
      "         -3.74433011e-01, -9.41478610e-02,  9.15417552e-01]],\n",
      "\n",
      "       [[ 2.78134167e-01, -1.01482844e+00, -1.35630870e+00, ...,\n",
      "          1.75970763e-01,  4.19818088e-02,  4.70950633e-01],\n",
      "        [ 7.45765090e-01, -1.16391170e+00, -3.95319879e-01, ...,\n",
      "         -1.39107212e-01,  2.07593203e-01,  9.75987554e-01],\n",
      "        [ 9.69206154e-01, -9.88797903e-01, -3.39552939e-01, ...,\n",
      "         -1.93859324e-01,  9.52368617e-01,  1.73680812e-01],\n",
      "        ...,\n",
      "        [ 7.83082128e-01, -1.00158155e+00, -7.55395949e-01, ...,\n",
      "         -4.31379974e-02,  4.60711271e-01,  1.32047570e+00],\n",
      "        [ 6.33348286e-01, -9.39310431e-01, -3.24846804e-01, ...,\n",
      "         -5.07731855e-01,  4.04301643e-01,  5.18811941e-01],\n",
      "        [ 9.97949243e-01,  1.15333423e-02, -3.10125947e-01, ...,\n",
      "         -3.89850467e-01, -8.43635350e-02,  8.70196939e-01]],\n",
      "\n",
      "       [[ 2.30401918e-01, -1.01334333e+00, -1.35256946e+00, ...,\n",
      "          2.18846932e-01,  4.31372337e-02,  4.56212044e-01],\n",
      "        [ 1.75014627e+00, -6.36825025e-01, -2.43468851e-01, ...,\n",
      "         -4.15797919e-01,  2.27540746e-01,  6.74758077e-01],\n",
      "        [ 1.30464661e+00, -7.34526336e-01, -1.31787193e+00, ...,\n",
      "         -7.20009029e-01,  5.76785803e-01,  9.83582318e-01],\n",
      "        ...,\n",
      "        [ 2.75183678e-01, -1.56007445e+00, -1.43866241e+00, ...,\n",
      "          4.92708720e-02,  4.21763122e-01,  1.01646519e+00],\n",
      "        [ 1.29404524e-02, -9.49693918e-01, -4.80845988e-01, ...,\n",
      "         -3.44488062e-02,  1.06124258e+00,  3.42315763e-01],\n",
      "        [ 8.56502116e-01,  1.28925085e-01,  7.61374757e-02, ...,\n",
      "         -8.81793201e-01, -4.45636101e-02,  9.71638858e-01]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 3.02342147e-01, -9.91505563e-01, -1.41132832e+00, ...,\n",
      "          1.80210739e-01,  7.46696666e-02,  4.44910407e-01],\n",
      "        [ 1.40958333e+00, -1.41269422e+00, -4.74204898e-01, ...,\n",
      "         -8.42201352e-01,  2.96385705e-01,  9.97092605e-01],\n",
      "        [ 4.53826755e-01, -6.31484032e-01, -8.16072762e-01, ...,\n",
      "         -3.99505228e-01,  4.90642458e-01,  9.59373951e-01],\n",
      "        ...,\n",
      "        [-1.00000000e+02, -1.00000000e+02, -1.00000000e+02, ...,\n",
      "         -1.00000000e+02, -1.00000000e+02, -1.00000000e+02],\n",
      "        [-1.00000000e+02, -1.00000000e+02, -1.00000000e+02, ...,\n",
      "         -1.00000000e+02, -1.00000000e+02, -1.00000000e+02],\n",
      "        [-1.00000000e+02, -1.00000000e+02, -1.00000000e+02, ...,\n",
      "         -1.00000000e+02, -1.00000000e+02, -1.00000000e+02]],\n",
      "\n",
      "       [[ 2.22993746e-01, -9.86520946e-01, -1.35632741e+00, ...,\n",
      "          1.66924357e-01,  3.12004946e-02,  4.62067723e-01],\n",
      "        [ 1.21910357e+00, -7.91198373e-01, -2.68565297e-01, ...,\n",
      "         -3.98195814e-03,  9.10411030e-02,  7.89455116e-01],\n",
      "        [ 3.02895546e-01, -1.04503787e+00, -6.35606766e-01, ...,\n",
      "         -7.00742006e-01,  4.61944729e-01,  7.04415679e-01],\n",
      "        ...,\n",
      "        [-1.00000000e+02, -1.00000000e+02, -1.00000000e+02, ...,\n",
      "         -1.00000000e+02, -1.00000000e+02, -1.00000000e+02],\n",
      "        [-1.00000000e+02, -1.00000000e+02, -1.00000000e+02, ...,\n",
      "         -1.00000000e+02, -1.00000000e+02, -1.00000000e+02],\n",
      "        [-1.00000000e+02, -1.00000000e+02, -1.00000000e+02, ...,\n",
      "         -1.00000000e+02, -1.00000000e+02, -1.00000000e+02]],\n",
      "\n",
      "       [[ 2.84331352e-01, -1.03940439e+00, -1.36613929e+00, ...,\n",
      "          1.20990068e-01,  9.89597174e-04,  4.78348255e-01],\n",
      "        [ 7.28839517e-01, -1.31774175e+00, -2.25747153e-02, ...,\n",
      "         -7.38487899e-01, -1.96676981e-02,  1.08734822e+00],\n",
      "        [ 7.37031698e-01, -1.29912806e+00, -6.64788485e-01, ...,\n",
      "         -8.28657746e-01,  6.19163290e-02,  8.32085907e-01],\n",
      "        ...,\n",
      "        [-1.00000000e+02, -1.00000000e+02, -1.00000000e+02, ...,\n",
      "         -1.00000000e+02, -1.00000000e+02, -1.00000000e+02],\n",
      "        [-1.00000000e+02, -1.00000000e+02, -1.00000000e+02, ...,\n",
      "         -1.00000000e+02, -1.00000000e+02, -1.00000000e+02],\n",
      "        [-1.00000000e+02, -1.00000000e+02, -1.00000000e+02, ...,\n",
      "         -1.00000000e+02, -1.00000000e+02, -1.00000000e+02]]],\n",
      "      dtype=float32), array([[[ 4.6991816e-01, -1.0530511e+00, -1.2029269e+00, ...,\n",
      "         -9.4847637e-01, -3.5624528e-01,  7.8266639e-01],\n",
      "        [ 8.7431270e-01, -1.1077732e+00, -3.5606924e-01, ...,\n",
      "         -1.4105786e+00, -5.8401716e-01,  1.0118772e+00],\n",
      "        [ 7.4482536e-01, -1.0777624e+00, -6.2280136e-01, ...,\n",
      "         -1.2159784e+00, -8.9403845e-02,  2.3178425e-01],\n",
      "        ...,\n",
      "        [ 6.4720839e-01, -1.1690987e+00, -7.9107606e-01, ...,\n",
      "         -8.0227572e-01, -2.8318658e-01,  1.0810957e+00],\n",
      "        [ 3.0896416e-01, -9.8299187e-01, -6.8543184e-01, ...,\n",
      "         -1.1957108e+00, -2.6983958e-01,  5.8932000e-01],\n",
      "        [ 7.6526785e-01, -4.0822810e-01, -6.4386261e-01, ...,\n",
      "         -1.0467427e+00, -6.2727457e-01,  7.3786259e-01]],\n",
      "\n",
      "       [[ 4.9686906e-01, -1.0596280e+00, -1.1890913e+00, ...,\n",
      "         -9.6216947e-01, -3.6670777e-01,  7.6050997e-01],\n",
      "        [ 5.7962018e-01, -1.2175779e+00, -4.9668485e-01, ...,\n",
      "         -9.7905141e-01, -5.3530002e-01,  8.5838133e-01],\n",
      "        [ 6.7116195e-01, -1.1244178e+00, -6.9017768e-01, ...,\n",
      "         -1.1611742e+00,  9.6567115e-03,  2.8121185e-01],\n",
      "        ...,\n",
      "        [ 6.7787868e-01, -1.1754317e+00, -7.8175604e-01, ...,\n",
      "         -8.1383961e-01, -2.8905830e-01,  1.0525260e+00],\n",
      "        [ 3.5484582e-01, -9.9006128e-01, -6.7908698e-01, ...,\n",
      "         -1.2001576e+00, -2.6920635e-01,  5.5601907e-01],\n",
      "        [ 7.9475874e-01, -4.2533877e-01, -6.3917363e-01, ...,\n",
      "         -1.0568568e+00, -6.2906182e-01,  7.0690614e-01]],\n",
      "\n",
      "       [[ 4.7955579e-01, -1.0625879e+00, -1.1826818e+00, ...,\n",
      "         -9.4928700e-01, -3.4409714e-01,  7.5919396e-01],\n",
      "        [ 1.1117358e+00, -8.8810158e-01, -5.1529264e-01, ...,\n",
      "         -1.2001150e+00, -4.9612191e-01,  6.2931716e-01],\n",
      "        [ 8.2345366e-01, -9.9649203e-01, -1.1250175e+00, ...,\n",
      "         -1.3685966e+00, -1.3527040e-01,  8.7041432e-01],\n",
      "        ...,\n",
      "        [ 5.0868106e-01, -1.5709085e+00, -1.1811152e+00, ...,\n",
      "         -7.5753838e-01, -2.2611684e-01,  9.1930658e-01],\n",
      "        [ 1.2469148e-01, -1.0413934e+00, -8.2134211e-01, ...,\n",
      "         -8.6231107e-01,  7.9437569e-02,  5.5599654e-01],\n",
      "        [ 6.5622920e-01, -4.5782557e-01, -4.0916568e-01, ...,\n",
      "         -1.3200312e+00, -7.2238964e-01,  7.3454589e-01]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 5.1510596e-01, -1.0329889e+00, -1.2277876e+00, ...,\n",
      "         -9.7739071e-01, -3.2760006e-01,  7.5774384e-01],\n",
      "        [ 1.0068920e+00, -1.1555841e+00, -5.5582780e-01, ...,\n",
      "         -1.5669656e+00, -4.2183834e-01,  8.1971622e-01],\n",
      "        [ 4.3189847e-01, -9.6351832e-01, -9.7218245e-01, ...,\n",
      "         -1.1074995e+00, -2.0806760e-01,  9.4435817e-01],\n",
      "        ...,\n",
      "        [-1.0000000e+02, -1.0000000e+02, -1.0000000e+02, ...,\n",
      "         -1.0000000e+02, -1.0000000e+02, -1.0000000e+02],\n",
      "        [-1.0000000e+02, -1.0000000e+02, -1.0000000e+02, ...,\n",
      "         -1.0000000e+02, -1.0000000e+02, -1.0000000e+02],\n",
      "        [-1.0000000e+02, -1.0000000e+02, -1.0000000e+02, ...,\n",
      "         -1.0000000e+02, -1.0000000e+02, -1.0000000e+02]],\n",
      "\n",
      "       [[ 4.6175537e-01, -1.0278426e+00, -1.1778086e+00, ...,\n",
      "         -9.6996862e-01, -3.5319233e-01,  7.6786757e-01],\n",
      "        [ 8.3255333e-01, -8.1604779e-01, -5.6010449e-01, ...,\n",
      "         -9.9434859e-01, -6.0945821e-01,  7.5302720e-01],\n",
      "        [ 4.4055539e-01, -1.0941544e+00, -8.6267948e-01, ...,\n",
      "         -1.4303473e+00, -2.5456035e-01,  6.7759109e-01],\n",
      "        ...,\n",
      "        [-1.0000000e+02, -1.0000000e+02, -1.0000000e+02, ...,\n",
      "         -1.0000000e+02, -1.0000000e+02, -1.0000000e+02],\n",
      "        [-1.0000000e+02, -1.0000000e+02, -1.0000000e+02, ...,\n",
      "         -1.0000000e+02, -1.0000000e+02, -1.0000000e+02],\n",
      "        [-1.0000000e+02, -1.0000000e+02, -1.0000000e+02, ...,\n",
      "         -1.0000000e+02, -1.0000000e+02, -1.0000000e+02]],\n",
      "\n",
      "       [[ 5.0307119e-01, -1.0567293e+00, -1.1823989e+00, ...,\n",
      "         -9.9658579e-01, -3.5861102e-01,  7.5861490e-01],\n",
      "        [ 5.3412777e-01, -1.1361326e+00, -3.4292036e-01, ...,\n",
      "         -1.3257903e+00, -5.1785141e-01,  9.2164224e-01],\n",
      "        [ 5.7087356e-01, -1.1990955e+00, -9.0810931e-01, ...,\n",
      "         -1.4482273e+00, -5.4959357e-01,  8.4948933e-01],\n",
      "        ...,\n",
      "        [-1.0000000e+02, -1.0000000e+02, -1.0000000e+02, ...,\n",
      "         -1.0000000e+02, -1.0000000e+02, -1.0000000e+02],\n",
      "        [-1.0000000e+02, -1.0000000e+02, -1.0000000e+02, ...,\n",
      "         -1.0000000e+02, -1.0000000e+02, -1.0000000e+02],\n",
      "        [-1.0000000e+02, -1.0000000e+02, -1.0000000e+02, ...,\n",
      "         -1.0000000e+02, -1.0000000e+02, -1.0000000e+02]]], dtype=float32), array([[[ 1.10465801e+00, -1.58762956e+00, -5.21870911e-01, ...,\n",
      "         -2.19215065e-01,  2.60640830e-01,  2.70707905e-01],\n",
      "        [ 1.40455163e+00, -1.55185950e+00,  2.45566815e-02, ...,\n",
      "         -4.60114777e-01,  1.48246855e-01,  4.17976350e-01],\n",
      "        [ 1.27033508e+00, -1.48521066e+00, -1.02532089e-01, ...,\n",
      "         -3.87024671e-01,  2.93656975e-01, -1.57528177e-01],\n",
      "        ...,\n",
      "        [ 1.16760087e+00, -1.54688394e+00, -2.59240210e-01, ...,\n",
      "         -8.93061236e-02,  2.88144588e-01,  4.63690221e-01],\n",
      "        [ 1.00814199e+00, -1.45816338e+00, -8.97198096e-02, ...,\n",
      "         -3.74856234e-01,  2.33724043e-01,  1.69990137e-01],\n",
      "        [ 1.30159307e+00, -1.05025387e+00, -1.52764618e-01, ...,\n",
      "         -2.48952910e-01,  6.53609782e-02,  2.11345345e-01]],\n",
      "\n",
      "       [[ 1.10809994e+00, -1.59391785e+00, -5.10559916e-01, ...,\n",
      "         -2.32517958e-01,  2.54873574e-01,  2.56185144e-01],\n",
      "        [ 1.16228902e+00, -1.58820295e+00, -1.10891812e-01, ...,\n",
      "         -2.89917260e-01,  1.18492410e-01,  3.11579645e-01],\n",
      "        [ 1.18217409e+00, -1.46008170e+00, -1.57446221e-01, ...,\n",
      "         -3.90515119e-01,  3.42525482e-01, -4.27956656e-02],\n",
      "        ...,\n",
      "        [ 1.17195213e+00, -1.55643618e+00, -2.51261532e-01, ...,\n",
      "         -1.05957605e-01,  2.83851177e-01,  4.46633607e-01],\n",
      "        [ 1.02087712e+00, -1.46783340e+00, -8.52216557e-02, ...,\n",
      "         -3.86573076e-01,  2.35878900e-01,  1.49406657e-01],\n",
      "        [ 1.30578780e+00, -1.06758344e+00, -1.47818759e-01, ...,\n",
      "         -2.63779253e-01,  6.59300834e-02,  1.93434268e-01]],\n",
      "\n",
      "       [[ 1.07576215e+00, -1.61248851e+00, -5.07434726e-01, ...,\n",
      "         -2.50574529e-01,  2.48373270e-01,  2.45726228e-01],\n",
      "        [ 1.54048538e+00, -1.42373717e+00, -7.40591064e-02, ...,\n",
      "         -4.62425619e-01,  5.56262806e-02,  1.32660687e-01],\n",
      "        [ 1.22384584e+00, -1.45642138e+00, -4.10628647e-01, ...,\n",
      "         -4.21161950e-01,  1.64356619e-01,  2.82970876e-01],\n",
      "        ...,\n",
      "        [ 9.47464406e-01, -1.86512685e+00, -4.57044184e-01, ...,\n",
      "         -1.55042127e-01,  2.58223772e-01,  4.06018823e-01],\n",
      "        [ 8.88691664e-01, -1.47809327e+00, -2.16505751e-01, ...,\n",
      "         -1.98942885e-01,  3.44967753e-01,  1.32395700e-01],\n",
      "        [ 1.18536568e+00, -1.13254845e+00,  9.07407515e-03, ...,\n",
      "         -4.90898997e-01,  1.72890059e-03,  2.54905760e-01]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 1.13763702e+00, -1.60144556e+00, -5.50592601e-01, ...,\n",
      "         -2.29363173e-01,  2.76646048e-01,  2.25301877e-01],\n",
      "        [ 1.58010590e+00, -1.59255159e+00, -1.71283305e-01, ...,\n",
      "         -5.88154316e-01,  1.66962862e-01,  2.15373710e-01],\n",
      "        [ 1.05049086e+00, -1.42293930e+00, -4.26383734e-01, ...,\n",
      "         -3.22872311e-01,  1.53127536e-01,  3.83668989e-01],\n",
      "        ...,\n",
      "        [-1.00000000e+02, -1.00000000e+02, -1.00000000e+02, ...,\n",
      "         -1.00000000e+02, -1.00000000e+02, -1.00000000e+02],\n",
      "        [-1.00000000e+02, -1.00000000e+02, -1.00000000e+02, ...,\n",
      "         -1.00000000e+02, -1.00000000e+02, -1.00000000e+02],\n",
      "        [-1.00000000e+02, -1.00000000e+02, -1.00000000e+02, ...,\n",
      "         -1.00000000e+02, -1.00000000e+02, -1.00000000e+02]],\n",
      "\n",
      "       [[ 1.08815110e+00, -1.58670437e+00, -4.94165152e-01, ...,\n",
      "         -2.30382219e-01,  2.45408669e-01,  2.49874547e-01],\n",
      "        [ 1.37785244e+00, -1.36646342e+00, -1.20939195e-01, ...,\n",
      "         -3.69066656e-01,  7.38108754e-02,  1.79468140e-01],\n",
      "        [ 1.03015721e+00, -1.44278717e+00, -2.70169228e-01, ...,\n",
      "         -4.52574432e-01,  1.51916727e-01,  1.82433397e-01],\n",
      "        ...,\n",
      "        [-1.00000000e+02, -1.00000000e+02, -1.00000000e+02, ...,\n",
      "         -1.00000000e+02, -1.00000000e+02, -1.00000000e+02],\n",
      "        [-1.00000000e+02, -1.00000000e+02, -1.00000000e+02, ...,\n",
      "         -1.00000000e+02, -1.00000000e+02, -1.00000000e+02],\n",
      "        [-1.00000000e+02, -1.00000000e+02, -1.00000000e+02, ...,\n",
      "         -1.00000000e+02, -1.00000000e+02, -1.00000000e+02]],\n",
      "\n",
      "       [[ 1.13060868e+00, -1.60180223e+00, -5.15448987e-01, ...,\n",
      "         -2.43946314e-01,  2.40876377e-01,  2.30752602e-01],\n",
      "        [ 1.18448615e+00, -1.63943708e+00, -7.60413632e-02, ...,\n",
      "         -4.98200774e-01,  1.32016480e-01,  2.27520257e-01],\n",
      "        [ 1.15689027e+00, -1.54945052e+00, -3.31186473e-01, ...,\n",
      "         -5.02083063e-01, -5.73485084e-02,  2.68509388e-01],\n",
      "        ...,\n",
      "        [-1.00000000e+02, -1.00000000e+02, -1.00000000e+02, ...,\n",
      "         -1.00000000e+02, -1.00000000e+02, -1.00000000e+02],\n",
      "        [-1.00000000e+02, -1.00000000e+02, -1.00000000e+02, ...,\n",
      "         -1.00000000e+02, -1.00000000e+02, -1.00000000e+02],\n",
      "        [-1.00000000e+02, -1.00000000e+02, -1.00000000e+02, ...,\n",
      "         -1.00000000e+02, -1.00000000e+02, -1.00000000e+02]]],\n",
      "      dtype=float32))), 'label_ids': array([[-100,    3,    4, ..., -100, -100, -100],\n",
      "       [-100,    0,    0, ..., -100, -100, -100],\n",
      "       [-100,    0,    0, ...,    0,    0, -100],\n",
      "       ...,\n",
      "       [-100,    0,    0, ..., -100, -100, -100],\n",
      "       [-100,    0,    0, ..., -100, -100, -100],\n",
      "       [-100,    0,    0, ..., -100, -100, -100]], dtype=int64), 'inputs': None}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\Lib\\site-packages\\seqeval\\metrics\\v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\Anaconda3\\Lib\\site-packages\\seqeval\\metrics\\v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.8500558137893677,\n",
       " 'eval_precision': 0.0,\n",
       " 'eval_recall': 0.0,\n",
       " 'eval_f1': 0.0,\n",
       " 'eval_accuracy': 0.8492268041237113,\n",
       " 'eval_runtime': 26.3152,\n",
       " 'eval_samples_per_second': 11.4,\n",
       " 'eval_steps_per_second': 1.444}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98674423",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "384px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
